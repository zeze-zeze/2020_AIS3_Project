{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import warnings\n",
    "from typing import Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.base import ClassifierMixin, RegressorMixin\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import (AdaBoostClassifier, BaggingClassifier,\n",
    "                              ExtraTreesClassifier, GradientBoostingClassifier,\n",
    "                              HistGradientBoostingClassifier,\n",
    "                              RandomForestClassifier)\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import (ARDRegression, BayesianRidge, HuberRegressor,\n",
    "                                  LinearRegression, LogisticRegression,\n",
    "                                  PassiveAggressiveClassifier,\n",
    "                                  PoissonRegressor, RidgeClassifier,\n",
    "                                  RidgeClassifierCV, SGDClassifier,\n",
    "                                  TheilSenRegressor, TweedieRegressor)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename: str) -> (np.ndarray, np.ndarray):\n",
    "    df = pd.read_csv(filename, header=None)\n",
    "    df[0] = df[0].apply(lambda x: int(\"evil\" in x))\n",
    "    data = df.to_numpy()\n",
    "    return data[:, 1:], data[:, 0]\n",
    "def dump_data(filename: str, X: np.ndarray, y: np.ndarray) -> None:\n",
    "    with open(filename, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for vec, label in zip(X, y):\n",
    "            writer.writerow([int(label)] + vec.tolist())\n",
    "def generate_data(n_samples: int=100, n_features: int=310) -> (np.ndarray, np.ndarray):\n",
    "    X, y = make_classification(n_samples=n_samples, n_features=n_features, n_informative=2, n_redundant=0,\n",
    "                               n_clusters_per_class=1, random_state=1)\n",
    "    X += 2 * np.random.RandomState(2).uniform(size=X.shape)\n",
    "    return X, y\n",
    "def load_model(filename: str) -> Union[ClassifierMixin, RegressorMixin]:\n",
    "    with open(filename, \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "    return model\n",
    "def dump_model(model: Union[ClassifierMixin, RegressorMixin], filename: str) -> None:\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "def reg2clf_elbow_method(y_pred: np.ndarray) -> np.ndarray:\n",
    "    indexed = np.array(list(zip(np.arange(len(y_pred)), y_pred)))\n",
    "    values_sort = indexed[indexed[:,1].argsort()]\n",
    "    value_diff = np.diff(values_sort[:,1])\n",
    "    high_pass = values_sort[np.argmax(value_diff)][1]\n",
    "    return y_pred > high_pass\n",
    "def prediction_func(model: Union[ClassifierMixin, RegressorMixin], asm_vecs: np.array) -> np.array:\n",
    "    predicted_results = model.predict(asm_vecs)\n",
    "    if isinstance(model, RegressorMixin):\n",
    "        y_pred = reg2clf_elbow_method(predicted_results)\n",
    "    else:\n",
    "        y_pred = predicted_results\n",
    "    return np.argwhere(y_pred==True).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, y = load_data(\"train_data/main_train_2.csv\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42)\n",
    "X_external, y_external = load_data(\"train_data/tmp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Calibrated CV\": CalibratedClassifierCV(),\n",
    "    \"QDA\": QuadraticDiscriminantAnalysis(),\n",
    "    \"Ada Boost\": AdaBoostClassifier(),\n",
    "    \"Bagging\": BaggingClassifier(),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Hist Gradient Boosting\": HistGradientBoostingClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    \"Gaussian Process\": GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    \"Passive Aggressive\": PassiveAggressiveClassifier(),\n",
    "    \"Ridge\": RidgeClassifier(),\n",
    "    \"Ridge CV\": RidgeClassifierCV(),\n",
    "    \"SGD\": SGDClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Neural Network\": MLPClassifier(alpha=1, max_iter=1000),\n",
    "    \"Linear SVM\": SVC(C=0.025, kernel=\"linear\"),\n",
    "    \"RBF SVM\": SVC(gamma=2),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Calibrated CV             - 0.000000 / 0.148148 - 0.727273 / 0.148148\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1.]\n",
      "QDA                       - 0.200000 / 0.000000 - 0.454545 / 0.518519\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1.]\n",
      "Ada Boost                 - 0.333333 / 0.250000 - 0.600000 / 0.703704\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 0.]\n",
      "Bagging                   - 0.636364 / 0.157895 - 0.781818 / 0.370370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "Extra Trees               - 0.800000 / 0.000000 - 0.836364 / 0.851852\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "Gradient Boosting         - 0.666667 / 1.000000 - 0.800000 / 0.888889\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Hist Gradient Boosting    - 0.600000 / 0.153846 - 0.781818 / 0.518519\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "Random Forest             - 0.500000 / 0.000000 - 0.727273 / 0.814815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "Gaussian Process          - 0.000000 / 0.000000 - 0.727273 / 0.851852\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "Passive Aggressive        - 0.000000 / 0.000000 - 0.727273 / 0.851852\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "Ridge                     - 0.000000 / 0.000000 - 0.727273 / 0.851852\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "Ridge CV                  - 0.000000 / 0.000000 - 0.727273 / 0.851852\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "SGD                       - 0.000000 / 0.148148 - 0.727273 / 0.148148\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1.\n",
      " 0. 1. 1.]\n",
      "Naive Bayes               - 0.375000 / 0.071429 - 0.581818 / 0.407407\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "Neural Network            - 0.000000 / 0.000000 - 0.727273 / 0.851852\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "Linear SVM                - 0.000000 / 0.000000 - 0.727273 / 0.851852\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "RBF SVM                   - 0.000000 / 0.000000 - 0.727273 / 0.851852\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0.\n",
      " 1. 1. 0.]\n",
      "Decision Tree             - 0.333333 / 0.222222 - 0.636364 / 0.481481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for classifier_name, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_pred_external = classifier.predict(X_external)\n",
    "#     print(classifier_name)\n",
    "#     print(classification_report(y_test, y_pred, target_names=[\"False\", \"True\"]))\n",
    "#     print(classification_report(y_external, y_pred_external, target_names=[\"False\", \"True\"]))\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_external = accuracy_score(y_external, y_pred_external)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    precision_external = precision_score(y_external, y_pred_external)\n",
    "    print(y_external)\n",
    "    print(y_pred_external)\n",
    "    print(f\"{classifier_name:25} - {precision:5f} / {precision_external:5f} - {accuracy:5f} / {accuracy_external:5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = {\n",
    "    \"Transformed Target\": TransformedTargetRegressor(),\n",
    "    \"PLSRegression\": PLSRegression(),\n",
    "    \"Kernel Ridge\": KernelRidge(alpha=1.0),\n",
    "    \"ARD\": ARDRegression(),\n",
    "    \"Bayesian Ridge\": BayesianRidge(),\n",
    "    \"Huber\": HuberRegressor(),\n",
    "    \"Linear\": LinearRegression(),\n",
    "    \"Logistic\": LogisticRegression(),\n",
    "    \"Poisson\": PoissonRegressor(),\n",
    "    \"TheilSen\": TheilSenRegressor(),\n",
    "    \"Tweedie\": TweedieRegressor(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for regressor_name, regressor in regressors.items():\n",
    "    regressor.fit(X_train, y_train)\n",
    "    predicted_results = regressor.predict(X_test)\n",
    "    y_pred = reg2clf_elbow_method(regressor.predict(X_test))\n",
    "    print(regressor_name)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted_results = regressor.predict(X_test)\n",
    "y_pred = reg2clf_elbow_method(regressor.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(y_pred==True).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(predicted_results)-1)\n",
    "plt.title(\"Matplotlib demo\")\n",
    "plt.xlabel(\"x axis caption\")\n",
    "plt.ylabel(\"y axis caption\")\n",
    "plt.plot(x,np.diff(predicted_results))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
